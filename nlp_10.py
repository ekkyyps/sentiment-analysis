# -*- coding: utf-8 -*-
"""nlp_10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YPRm9__tyrbb9nTw11F6sEaapNWbYdu9
"""

pip install Sastrawi

import csv
import numpy as np

import pandas as pd

df = pd.read_csv("/content/dataset.csv", nrows=700)
df

df.shape

df.Sentiment.value_counts()

import seaborn as sns
sns.countplot(x='Sentiment', data=df)

sns.countplot(x='Pasangan Calon', data=df)

tweet = df['Text Tweet']
sentimen = df['Sentiment']

"""Preprocessing"""

import nltk
nltk.download("stopwords")
import re
import Sastrawi
from nltk.tokenize import TweetTokenizer
from nltk.corpus import stopwords
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory

def stopword(stopwordsfile):
    stopwords=[]
    file_stopwords = open(stopwordsfile,'r')
    row = file_stopwords.readline()
    while row:
        word = row.strip()
        stopwords.append(word)
        row = file_stopwords.readline()
    file_stopwords.close()
    return stopwords

stopwords_indo = stopword('stopwords.txt')

# Commented out IPython magic to ensure Python compatibility.
# # Case Folding
# %%time
# X_lower = tweet.str.lower() #lowercase
# X_num = X_lower.apply(lambda x: re.sub(r"\d+", "", str(x))) #delete numbers
# X_sign = X_num.apply(lambda x: re.sub(r'\W', ' ', str(x))) #punctuation

# Commented out IPython magic to ensure Python compatibility.
# # Tokenization
# %%time
# tweet_tokenizer = TweetTokenizer()
# tweet_tokens = X_sign.apply(lambda x: tweet_tokenizer.tokenize(x))

# Commented out IPython magic to ensure Python compatibility.
# # Stopwords Removal
# %%time
# tokens = tweet_tokens.apply(lambda x: [w for w in x if w not in stopwords_indo])

# Commented out IPython magic to ensure Python compatibility.
# # Stemming
# %%time
# factory = StemmerFactory()
# stemmer = factory.create_stemmer()
# for k in tokens:
#     for l in k: 
#       l = stemmer.stem(l)
# # print(tokens)

"""Split dataset"""

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(tokens,sentimen,test_size=0.2)

"""Klasifikasi"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer
from sklearn.metrics import f1_score, make_scorer,accuracy_score, classification_report, confusion_matrix
from imblearn.pipeline import make_pipeline as make_pipeline_imb
from sklearn.pipeline import Pipeline

def identity_tokenizer(text):
    return text
    
text_clf = Pipeline([('vect', TfidfVectorizer(tokenizer=identity_tokenizer, lowercase=False)),
                     ('clf', MultinomialNB()),
                     ])
tuned_parameters = {
    'vect__min_df': [5,6,7,8,9,10], 
    'vect__max_df': [0.25, 0.5, 0.75], 
    'vect__sublinear_tf': [True, False], 
    'vect__smooth_idf': [True, False],
    'vect__use_idf': [True, False], 
    'vect__analyzer': ['word', 'char', 'char_wb'], 
    'vect__norm': ['l1','l2'],
    'vect__ngram_range' : [(1, 1), (1, 2), (1, 3), (1,4), (1, 5),(1, 6)],
    'vect__use_idf': (True, False),
    'vect__norm': ('l1', 'l2'),
    'clf__alpha': np.linspace(0.5, 1.5, 6),
    'clf__fit_prior': [True, False],  
}

"""NB Classifier"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# pipe = make_pipeline_imb(TfidfVectorizer(tokenizer=identity_tokenizer, lowercase=False),
#                          TfidfTransformer(),MultinomialNB())
# 
# pipe.fit(X_train, y_train)
# y_pred_NB = pipe.predict(X_test)
# results = confusion_matrix(y_test, y_pred_NB) 
# print('Confusion Matrix:')
# print(results)
# print('Report:')
# report = classification_report(y_test, y_pred_NB, digits=4)
# print(report)

result_class = pd.DataFrame({
    'Actual Result': y_test,
    'Naive Bayes': y_pred_NB,
})
result_class

result_class.to_excel("result_class.xlsx")

X_train2,X_test2,y_train2,y_test2 = train_test_split(tokens,sentimen,test_size=0.3)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# pipe = make_pipeline_imb(TfidfVectorizer(tokenizer=identity_tokenizer, lowercase=False),
#                          TfidfTransformer(),MultinomialNB())
# 
# pipe.fit(X_train2, y_train2)
# y_pred_NB2 = pipe.predict(X_test2)
# results2 = confusion_matrix(y_test2, y_pred_NB2) 
# print('Confusion Matrix:')
# print(results2)
# print('Report:')
# report2 = classification_report(y_test2, y_pred_NB2, digits=4)
# print(report2)

result_class2 = pd.DataFrame({
    'Actual Result': y_test2,
    'Naive Bayes': y_pred_NB2,
})
result_class2

result_class2.to_excel("result_class2.xlsx")